# 第四章 分类：基本概念、决策树与模型评估
## 预备知识
1. 定义4.1 分类：分类任务就是通过学习得到一个目标函数f，把每个属性集x映射到一个预先定义好的类标号y.目标函数也称分类模型。 __分类模型__ 可用于 __描述性建模__ __预测性建模__
## 解决分类问题的一般方法
分类法的例子包括决策树分类法、基于规则的分类法、神经网络、支持向量机和朴素贝叶斯分类法。这些技术都使用一种学习算法确定分类模型，
![建立分类模型的一般方法](分类模型一般方法.jpg)
## 决策树归纳
决策树分类法——一种但却广泛使用的分类技术
### 原理
决策树有三种结点
1. 根节点，它没有入边，但有零边或多条出边
2. 内部结点，恰有一条入边和两条或多条出边
3. 叶结点或终结点，恰有一条入边，没有出边

每个叶结点都赋予一个类标号。非终结点包含属性测试条件
<img src="哺乳动物分类问题的决策树.jpg" style="max-width:70%"></img>
### 建立决策树
#### Hunt算法
1. 首先选择根节点,再选择一个属性测试条件进行分支
2. 叶结点的判定:所有记录同属一个类,如果不是叶结点,就继续选择属性,进行测试与分支
3. 直到底部都是叶节点

属性测试有其方法:根据属性的类型选择
* 二元属性
* 标称属性
* 序数属性
* 连续属性
![决策树代码](决策树code.jpg)

其他需要注意的:建立决策树之后,可以进行 __树剪枝__ ,以减小决策树规模,决策树过大容易引起 __过分拟合__ 
## 模型的过拟合
过拟合的模型虽然有更多的结点,更好的训练误差,但是检验误差(泛化误差)不行,因为受到样本的噪声干扰,生成了很多噪声结点,降低了模型的性能.
1. 噪声导致的过拟合
2. 缺乏代表性样本导致的过拟合

因此需要正确地评估泛化误差
1. 使用再代入估计
2. 结合模型复杂度.
    * 悲观误差评估
    * 最小描述长度原则
3. 估计统计上界.泛化误差倾向于比训练误差大,所以统计修正通常是计算训练误差的上界.
4. 使用确认集.典型的做法是保留2/3的训练集来建立模型,剩余1/3用作误差估计

评估之后,要对决策树进行处理
1. 先剪枝(提前终止规则),符合评估标准立刻停止扩展叶结点
2. 后剪枝
    * 用新的叶结点替换子树,该叶结点的类标号由子树下记录的多数类确定
    * 用子树中最常用的分支代替子树.

# 第五章 分类:其他技术
## 贝叶斯分类器
### 贝叶斯定理
公式:P(Y|X) = P(X|Y)P(Y)/P(X)
### 贝叶斯定理在分类中的应用

## 人工神经网络(NN)
## 支持向量机(SVM)